# DeepResearchAgent æ·±åº¦ç ”ç©¶ä»£ç†æœåŠ¡æ¨¡æ¿

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

DeepResearchAgent æ˜¯ä¸€ä¸ªåŸºäº ReAct (Reasoning and Acting) æ¡†æ¶çš„é€šç”¨æ·±åº¦ç ”ç©¶ä»£ç†æœåŠ¡æ¨¡æ¿ï¼Œå†…ç½® MCPï¼ˆModel Context Protocolï¼‰å·¥å…·è°ƒç”¨æ¡†æ¶ä¸æµå¼è¾“å‡ºèƒ½åŠ›ï¼Œå¯ç”¨äºæ„å»ºå¯æ’æ‹”çš„ç ”ç©¶å‹æ™ºèƒ½ä½“æœåŠ¡ã€‚

## æ ¸å¿ƒç‰¹æ€§

### æ·±åº¦ç ”ç©¶ä»£ç†
- **å¤šåœºæ™¯åˆ†ç±»æ”¯æŒ**: æ–‡æ¡£é˜…è¯»ã€é—®é¢˜åˆ†æã€è§„åˆ’åˆ¶å®šã€å†³ç­–å»ºè®®ã€æŠ€æœ¯æ’éšœç­‰
- **å¹¶è¡Œå·¥ä½œæµå¤„ç†**: æ”¯æŒå¤šåˆ†ç±»å¹¶å‘æ‰§è¡Œï¼Œæé«˜ååä¸å“åº”æ•ˆç‡
- **å®ä½“è¯†åˆ«**: è‡ªåŠ¨æå–å…³é”®å®ä½“ä¸ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¾…åŠ©åç»­æ£€ç´¢ä¸è§„åˆ’

### ReActæ¡†æ¶
- **æ¨ç†-è¡ŒåŠ¨å¾ªç¯**: æ¨¡æ‹Ÿäººç±»ä¸“å®¶çš„æ€è€ƒå’Œå†³ç­–è¿‡ç¨‹
- **å·¥å…·é“¾é›†æˆ**: ä¸°å¯Œçš„MCPå·¥å…·è°ƒç”¨ï¼Œæ”¯æŒå¤šç§ä¸“ä¸šæŸ¥è¯¢
- **æµå¼å¤„ç†**: å®æ—¶æµå¼å“åº”ï¼Œç”¨æˆ·ä½“éªŒä¼˜ç§€

### æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)
- **æ··åˆæ£€ç´¢**: å‘é‡æ£€ç´¢ + BM25å…¨æ–‡æ£€ç´¢
- **RRFèåˆç®—æ³•**: Reciprocal Rank Fusion ä¼˜åŒ–æ£€ç´¢ç»“æœ
- **Elasticsearché›†æˆ**: é«˜æ•ˆçš„å‘é‡å’Œæ–‡æœ¬æ£€ç´¢

### APIæœåŠ¡
- **FastAPIæ¡†æ¶**: ç°ä»£åŒ–ã€é«˜æ€§èƒ½çš„APIæœåŠ¡
- **SSEæµå¼å“åº”**: Server-Sent Events æ”¯æŒå®æ—¶æ•°æ®æ¨é€
- **å¤–éƒ¨APIé›†æˆ**: æ”¯æŒå¤šç§ç¬¬ä¸‰æ–¹æœåŠ¡è°ƒç”¨

## DeepResearchAgent æŠ€æœ¯æ–¹æ¡ˆ

### å®Œæ•´å·¥ä½œæµç¨‹

ç³»ç»Ÿå¤„ç†ç”¨æˆ·è¾“å…¥çš„å®Œæ•´æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

```mermaid
graph TB
    %% ==================== ç”¨æˆ·è¾“å…¥ä¸é¢„å¤„ç† ====================
    A[ç”¨æˆ·è¾“å…¥] --> B{è¾“å…¥ç±»å‹æ£€æµ‹}
    B -->|JSONæ ¼å¼| C[JSONè§£æ<br/>æå–å…ƒæ•°æ®/é™„ä»¶ç­‰]

    B -->|æ™®é€šæ–‡æœ¬| D[ç›´æ¥ä½œä¸ºè¾“å…¥]
    C --> E[å­˜å‚¨å…ƒæ•°æ®åˆ°ä¸Šä¸‹æ–‡<br/>input_metadata]
    D --> E

    %% ==================== æ„å›¾è¯†åˆ«ä¸åœºæ™¯åˆ†ç±» ====================
    E --> F[æ„å›¾è¯†åˆ«LLM<br/>intent_recognition_llm]
    F --> G[æµå¼è§£æå™¨<br/>æ€è€ƒ/è¾“å‡ºåˆ†ç¦»]
    G --> H{æ˜¯å¦è§¦å‘å¿«é€Ÿå“åº”?}
    H -->|æ˜¯| I[ç›´æ¥è¿”å›æ ‡å‡†ç­”æ¡ˆ<br/>StopEvent]
    I --> END1[è¿”å›ç»“æœ<br/>ç»“æŸå·¥ä½œæµ]
    H -->|å¦| J{åˆ¤æ–­åˆ†ç±»æ¨¡å¼}

    %% ==================== åœºæ™¯åˆ†ç±»æœºåˆ¶ ====================
    J -->|å•åˆ†ç±»| K[å®ä½“è¯†åˆ«é˜¶æ®µ]
    J -->|å¤šåˆ†ç±»å¹¶è¡Œ| K1[è¯†åˆ«å¤šä¸ªåˆ†ç±»<br/>research-documentã€research-problemã€research-planning ç­‰]

    K1 --> K2[åˆ›å»ºå¹¶è¡Œå·¥ä½œæµç®¡ç†å™¨<br/>ParallelWorkflowManager]
    K2 --> K3{ä¸ºæ¯ä¸ªåˆ†ç±»åˆ›å»º}
    K3 --> K4A[åˆ†ç±»Aç‹¬ç«‹Agentå®ä¾‹<br/>+ç‹¬ç«‹LLM+ç‹¬ç«‹ä¸Šä¸‹æ–‡]
    K3 --> K4B[åˆ†ç±»Bç‹¬ç«‹Agentå®ä¾‹<br/>+ç‹¬ç«‹LLM+ç‹¬ç«‹ä¸Šä¸‹æ–‡]
    K3 --> K4C[åˆ†ç±»Cç‹¬ç«‹Agentå®ä¾‹<br/>+ç‹¬ç«‹LLM+ç‹¬ç«‹ä¸Šä¸‹æ–‡]

    K4A --> K5[å¹¶è¡Œæ‰§è¡Œå„åˆ†ç±»å·¥ä½œæµ]
    K4B --> K5
    K4C --> K5
    K5 --> K6[ç­‰å¾…æ‰€æœ‰åˆ†ç±»å®Œæˆæˆ–è¶…æ—¶]
    K6 --> K7[åˆå¹¶å„åˆ†ç±»ç»“æœ]
    K7 --> END1

    %% ==================== å®ä½“è¯†åˆ«é˜¶æ®µ ====================
    K --> L[å®ä½“è¯†åˆ«LLM<br/>entity_recognition_llm]
    L --> M[æµå¼è§£æå™¨<br/>æ€è€ƒ/è¾“å‡ºåˆ†ç¦»]
    M --> N[è§£æJSONå®ä½“åˆ—è¡¨<br/>å®ä½“åç§°/ç±»å‹/ä¸Šä¸‹æ–‡]

    N --> O[åˆå¹¶è¯†åˆ«å®ä½“åˆ°å…ƒæ•°æ®<br/>_merge_entities_to_metadata]
    O --> P[æŒ‰è®¾å¤‡ç±»å‹é€‰æ‹©å·¥ä½œæµæ¨¡æ¿<br/>get_workflow_template_by_device_type]

    %% ==================== è®¡åˆ’ç”Ÿæˆé˜¶æ®µ ====================
    P --> Q[è®¡åˆ’ç”ŸæˆLLM<br/>planning_llm]
    Q --> R[æ³¨å…¥MCPå·¥å…·æè¿°+æ¨¡æ¿+å…ƒæ•°æ®<br/>åŸºäºcategoryè¿‡æ»¤å·¥å…·é»‘åå•]
    R --> S[æµå¼è®¡åˆ’ç”Ÿæˆ]
    S --> T[ä¿å­˜current_planåˆ°ä¸Šä¸‹æ–‡]

    %% ==================== ReActæ¨ç†å¾ªç¯æ ¸å¿ƒ ====================
    T --> U[å‡†å¤‡èŠå¤©å†å²<br/>prepare_chat_history]
    U --> V[æ ¼å¼åŒ–LLMè¾“å…¥<br/>ç³»ç»Ÿæç¤º+å†å²+æ¨ç†+å…ƒæ•°æ®+è¿‡æ»¤åå·¥å…·]
    V --> W[ReActæ¨ç†LLM<br/>ä¸»LLMå®ä¾‹]
    W --> X[æµå¼è§£æå™¨<br/>æ€è€ƒ/è¡ŒåŠ¨åˆ†ç¦»]
    X --> Y{è§£ææ¨ç†æ­¥éª¤}

    %% ==================== æ¨ç†æ­¥éª¤åˆ†æ”¯ ====================
    Y -->|å·¥å…·è°ƒç”¨ Action| Z[æå–å·¥å…·åç§°å’Œå‚æ•°]
    Y -->|é‡Œç¨‹ç¢‘ Milestone| Z1[çŠ¶æ€æ›´æ–°<br/>ç»§ç»­æ¨ç†å¾ªç¯]
    Y -->|å®Œæˆ Final| Z2[æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ]
    Y -->|è§£æé”™è¯¯| Z3[é”™è¯¯å¤„ç†<br/>æ·»åŠ é”™è¯¯è§‚å¯Ÿ]

    %% ==================== å·¥å…·è°ƒç”¨å¤„ç†ï¼ˆMCPåè®®ï¼‰ ====================
    Z --> AA[MCPå®¢æˆ·ç«¯è¿æ¥æ£€æŸ¥<br/>ensure_connected]
    AA --> AB[å‘é€MCPå·¥å…·è°ƒç”¨è¯·æ±‚<br/>HTTPè¿œç¨‹è°ƒç”¨]
    AB --> AC{å·¥å…·ç±»å‹ç‰¹æ®Šå¤„ç†}

    %% ==================== æ··åˆæ£€ç´¢å·¥å…·å¤„ç† ====================
    AC -->|search_documents| AD[ESæ··åˆæ£€ç´¢æ¨¡å¼<br/>_es_full_text_search]

    AD --> AD1[ç”ŸæˆæŸ¥è¯¢å‘é‡ 1024ç»´]
    AD1 --> AD2[å¹¶è¡Œæ‰§è¡Œæ£€ç´¢]
    AD2 --> AD3[å‘é‡æ£€ç´¢kNN<br/>å¬å›Top-20å€™é€‰<br/>cosineç›¸ä¼¼åº¦]
    AD2 --> AD4[å…¨æ–‡æ£€ç´¢BM25<br/>å¬å›Top-20å€™é€‰]
    AD3 --> AD5[æ‰‹åŠ¨RRFèåˆç®—æ³•<br/>_manual_rrf_fusion]
    AD4 --> AD5
    AD5 --> AD6[è®¡ç®—RRFåˆ†æ•°score]
    AD6 --> AD7[è¿”å›Top-15èåˆç»“æœ<br/>åŒ…å«vector_rank+text_rank]
    AD7 --> AD8[å¤šçº¿ç¨‹å¹¶è¡Œè¿‡æ»¤<br/>_filter_chunks_parallel]
    AD8 --> AD9[æ¯æ‰¹3ä¸ªchunk<br/>æœ€å¤š3ä¸ªçº¿ç¨‹<br/>filter_llmåˆ¤æ–­ç›¸å…³æ€§]
    AD9 --> AD10[ç¼“å­˜relevant_doc_chunks<br/>è¿½åŠ åˆ°sources]

    %% ==================== å…¶ä»–å·¥å…·å¤„ç† ====================
    AC --> AR[è§£ææ¨¡å‹æ„é€ å‚æ•°]
    AR --> AS[æ³¨å…¥ç›¸åº”ç¼“å­˜å‚æ•°]
    AS --> AI[å…¶ä»–mcpå·¥å…·æ ‡å‡†è°ƒç”¨]

    AI --> AJ[æ ‡å‡†ç»“æœå¤„ç†]
    AD10 --> AJ

    %% ==================== è§‚å¯Ÿç»“æœå¤„ç†ä¸å¾ªç¯ ====================
    AJ --> AK[æ·»åŠ ObservationReasoningStep<br/>å·¥å…·è§‚å¯Ÿç»“æœ]
    AK --> AL[æ›´æ–°æ¨ç†å†å²<br/>current_reasoning]
    AL --> AM[å·¥ä½œæµç­–ç•¥å›è°ƒ<br/>on_tool_call_complete]
    AM --> U
    Z1 --> U
    Z3 --> U

    %% ==================== æœ€ç»ˆç»“æœç”Ÿæˆ ====================
    Z2 --> AN[æ„å»ºæœ€ç»ˆå“åº”]
    AN --> AO[åŒ…å«ç­”æ¡ˆ+æ¥æº+æ¨ç†å†å²]
    AO --> AQ[æŒ‰åˆ†ç±»æŒä¹…åŒ–åˆ°æ•°æ®åº“]
    AQ --> AP[StopEventè§¦å‘]
    AP --> END2[è¿”å›å®Œæ•´ç»“æœ<br/>ç»“æŸå·¥ä½œæµ]

    %% ==================== æ ·å¼å®šä¹‰ ====================
    classDef inputProcessing fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef intentRecognition fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    classDef parallelWorkflow fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef entityRecognition fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    classDef planning fill:#dcedc8,stroke:#689f38,stroke-width:2px
    classDef reactCore fill:#bbdefb,stroke:#1565c0,stroke-width:2px
    classDef toolCall fill:#ffe0b2,stroke:#ef6c00,stroke-width:2px
    classDef hybridSearch fill:#ffccbc,stroke:#d84315,stroke-width:3px
    classDef streaming fill:#e1bee7,stroke:#6a1b9a,stroke-width:2px
    classDef errorHandling fill:#ffcdd2,stroke:#c62828,stroke-width:2px
    classDef finalResult fill:#c5e1a5,stroke:#558b2f,stroke-width:2px

    %% ==================== åº”ç”¨æ ·å¼ ====================
    class A,B,C,D,E inputProcessing
    class F,G,H,I,J intentRecognition
    class K1,K2,K3,K4A,K4B,K4C,K5,K6,K7 parallelWorkflow
    class K,L,M,N,O entityRecognition
    class P,Q,R,S,T planning
    class U,V,W,X,Y,Z1,Z3 reactCore
    class Z,AA,AB,AC,AJ,AK,AL,AM toolCall
    class AD,AD1,AD2,AD3,AD4,AD5,AD6,AD7,AD8,AD9,AD10 hybridSearch
    class AE,AF,AG,AH,AI,AR,AS toolCall
    class G,M,S,X streaming
    class Z3 errorHandling
    class Z2,AN,AO,AQ,AP,END1,END2 finalResult
```

### æµç¨‹è¯´æ˜

#### é˜¶æ®µä¸€: ç”¨æˆ·è¾“å…¥ä¸é¢„å¤„ç†

**æ ¸å¿ƒåŠŸèƒ½**: æ¥æ”¶å¹¶è§£æç”¨æˆ·è¾“å…¥ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯

**ä»£ç å®ç°**ï¼š

```python
# æ£€æµ‹è¾“å…¥ç±»å‹å¹¶è§£æ
async def preprocess_input(user_input: str) -> Dict:
    try:
        # å°è¯•è§£æä¸ºJSONæ ¼å¼
        parsed_data = dirtyjson.loads(user_input)
        query = parsed_data.get("query", "")
        metadata = parsed_data.get("metadata", {})
    except:
        # æ™®é€šæ–‡æœ¬æ ¼å¼
        query = user_input
        metadata = {}
    
    # å­˜å‚¨åˆ°ä¸Šä¸‹æ–‡
    await ctx.store.set("user_input", query)
    await ctx.store.set("input_metadata", metadata)
    return {"query": query, "metadata": metadata}
```

**å…³é”®ç‰¹æ€§**ï¼š

1.  **å®¹é”™JSONè§£æ**: ä½¿ç”¨`dirtyjson`åº“å¤„ç†æ ¼å¼ä¸è§„èŒƒçš„JSONè¾“å…¥
    
2.  **å¤šæ ¼å¼æ”¯æŒ**: è‡ªåŠ¨è¯†åˆ«JSON/æ™®é€šæ–‡æœ¬è¾“å…¥ç±»å‹
    
3.  **ä¸Šä¸‹æ–‡å­˜å‚¨**: é€šè¿‡`ctx.store`æŒä¹…åŒ–ç”¨æˆ·è¾“å…¥å’Œå…ƒæ•°æ®
    

#### é˜¶æ®µäºŒ: åˆ†ç±»è¯†åˆ«ä¸å¿«é€Ÿå“åº”

**æ ¸å¿ƒåŠŸèƒ½**: è¯†åˆ«ç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼Œå¯¹æ ‡å‡†é—®é¢˜å¿«é€Ÿå“åº”ï¼Œå¹¶åˆ¤æ–­æ‰€éœ€è¦æ‰§è¡Œçš„æµç¨‹åˆ†ç±»

**ä»£ç å®ç°**ï¼š

```python
async def recognize_intent(user_input: str) -> str:
    # è°ƒç”¨Intent LLM(æµå¼)
    response_stream = await intent_recognition_llm.stream_chat([
        {"role": "system", "content": INTENT_RECOGNITION_TEMPLATE},
        {"role": "user", "content": user_input}
    ])
    
    # å®æ—¶è§£ææ€è€ƒå’Œè¾“å‡º
    parser = StreamingResponseParser()
    async for chunk in response_stream:
        thinking, output = parser.parse(chunk)  # åˆ†ç¦» <think>æ€è€ƒ</think> å’Œè¾“å‡º
        if thinking:
            await sse_manager.send_event("thinking", {"content": thinking})
    
    # å¿«é€Ÿå“åº”åˆ¤æ–­
    if is_standard_question(intent_result):
        return StopEvent(result=get_standard_answer(intent_result))
```

**å¿«é€Ÿå“åº”æœºåˆ¶**: è¯†åˆ«åˆ°æ ‡å‡†é—®é¢˜ç›´æ¥è¿”å›`StopEvent`,è·³è¿‡åç»­æ¨ç†

**è‡ªåŠ¨åˆ†ç±»**: æ ¹æ®ç”¨æˆ·éœ€æ±‚ç±»å‹è‡ªåŠ¨æ ‡æ³¨ workflow åˆ†ç±»ï¼ˆå¦‚ research-document / research-problem / research-planningï¼‰

#### é˜¶æ®µä¸‰: å®ä½“è¯†åˆ«

**æ ¸å¿ƒåŠŸèƒ½**: ä»è‡ªç„¶è¯­è¨€ä¸­æå–ç»“æ„åŒ–å®ä½“ä¿¡æ¯

**è¾“å‡ºç¤ºä¾‹**ï¼š

```json
[{"entity_name":"React","entity_type":"æŠ€æœ¯","context_info":"å¯¹æ¯”ä¸é€‰å‹","entity_category":"æŠ€æœ¯"}]
```

#### é˜¶æ®µå››: è®¡åˆ’ç”Ÿæˆ

**æ ¸å¿ƒåŠŸèƒ½**: æ ¹æ®è®¾å¤‡ç±»å‹å’Œåˆ†ç±»ï¼Œå‚è€ƒå†å²çš„æ‰§è¡Œè®¡åˆ’ç¤ºä¾‹ï¼Œç”Ÿæˆæ–°çš„æ‰§è¡Œè®¡åˆ’

**ç”Ÿæˆè®¡åˆ’ç¤ºä¾‹**ï¼š

```plaintext
ã€æ‰§è¡Œè®¡åˆ’ã€‘é’ˆå¯¹â€œå¦‚ä½•è®¾è®¡ä¸€ä¸ªå¯æ’æ‹”çš„æ·±åº¦ç ”ç©¶ä»£ç†æœåŠ¡ï¼Ÿâ€
- [ ] ä½¿ç”¨ `search_documents` å·¥å…·æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„èµ„æ–™ç‰‡æ®µ
- [ ] ä½¿ç”¨ `conclude_document_chunks` å·¥å…·å¯¹æ£€ç´¢åˆ°çš„ç‰‡æ®µåšå½’çº³æ€»ç»“
- [ ] åŸºäºæ€»ç»“ç»“æœè¾“å‡ºç»“æ„åŒ–ç»“è®ºä¸å»ºè®®
```

#### é˜¶æ®µäº”: ReActæ¨ç†å¾ªç¯

**å·¥ä½œåŸç†**: AIè‡ªä¸»æ¨ç†ã€å·¥å…·è°ƒç”¨ã€ç»“æœè§‚å¯Ÿçš„è¿­ä»£å¾ªç¯

```python
async def react_reasoning_loop(user_input: str, category: str):
    max_iterations = 50
    iteration = 0
    
    while iteration < max_iterations:
        iteration += 1
        
        # 1. å‡†å¤‡èŠå¤©å†å²
        chat_history = await prepare_chat_history(ctx)
        
        # 2. è°ƒç”¨Main LLM(æµå¼)
        response_stream = await main_llm.stream_chat(messages)
        
        # 3. å®æ—¶è§£ææ¨ç†æ­¥éª¤
        parser = customReActOutputParser()
        async for chunk in response_stream:
            thinking, action = parser.parse(chunk)
            if thinking:
                await sse_manager.send_event("thinking", {"content": thinking})
        
        # 4. æ ¹æ®æ¨ç†æ­¥éª¤æ‰§è¡Œ
        if isinstance(reasoning_step, ActionReasoningStep):
            await handle_tool_call(ctx, reasoning_step)  # å·¥å…·è°ƒç”¨
        elif reasoning_step.is_done:
            return StopEvent(result=reasoning_step.response)  # å®Œæˆ
```

**æ¨ç†å¾ªç¯ç¤ºä¾‹**ï¼š

```plaintext
ç¬¬1è½®: æ€è€ƒâ†’éœ€è¦æ£€ç´¢ç›¸å…³æ–‡æ¡£ | è¡ŒåŠ¨â†’è°ƒç”¨æ£€ç´¢å·¥å…· | è§‚å¯Ÿâ†’è·å¾—15ä¸ªæ–‡æ¡£
ç¬¬2è½®: æ€è€ƒâ†’éœ€è¦æå–å…³è”è®¾å¤‡ | è¡ŒåŠ¨â†’è°ƒç”¨æå–å·¥å…· | è§‚å¯Ÿâ†’è·å¾—å…³è”ç”µå‚åˆ—è¡¨
ç¬¬3è½®: æ€è€ƒâ†’ä¿¡æ¯å……è¶³ | è¡ŒåŠ¨â†’è°ƒç”¨ç»“è®ºç”Ÿæˆ | è§‚å¯Ÿâ†’ç”Ÿæˆå®Œæ•´ç­”æ¡ˆ
ç¬¬4è½®: æ€è€ƒâ†’ä»»åŠ¡å®Œæˆ | è¡ŒåŠ¨â†’Finish | æ¨ç†å¾ªç¯ç»“æŸ
```

#### é˜¶æ®µå…­: æ··åˆæ£€ç´¢

**æ ¸å¿ƒæŠ€æœ¯**: å‘é‡æ£€ç´¢ + å…¨æ–‡æ£€ç´¢ + RRFèåˆ

**ä»£ç å®ç°**ï¼š

```python
async def hybrid_search(query: str, category: str):
    # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡(1024ç»´)
    query_vector = embedder._get_query_embedding(query)
    
    # 2.1 å‘é‡æ£€ç´¢ (kNN)
    vector_results = await es_client.search({
        "knn": {"field": "embedding", "query_vector": query_vector, "k": 50}
    })
    
    # 2.2 å…¨æ–‡æ£€ç´¢ (BM25)
    text_results = await es_client.search({
        "query": {"bool": {"must": [{"match": {"chunk": query}}]}}
    })
    
    # 3. RRFèåˆ
    return _manual_rrf_fusion(vector_results, text_results, k=10, top_n=15)
```

**RRFèåˆç®—æ³•**ï¼š

```python
def _manual_rrf_fusion(vector_results, text_results, k=10, top_n=15):
    # å…¬å¼: score(d) = Î£ [1 / (k + rank_i(d))]
    for item in vector_results:
        doc_dict[doc_id]['rrf_score'] += 1.0 / (k + item['vector_rank'])
    for item in text_results:
        doc_dict[doc_id]['rrf_score'] += 1.0 / (k + item['text_rank'])
    # æŒ‰RRFåˆ†æ•°æ’åº,è¿”å›Top-N
    return sorted_docs[:top_n]
```

**å…³é”®ç‰¹æ€§**ï¼š

1.  **åŒè·¯å¹¶è¡Œæ£€ç´¢**: å‘é‡æ£€ç´¢(kNN + Cosine, Top-50å€™é€‰) + å…¨æ–‡æ£€ç´¢(BM25, Top-50å€™é€‰)
    
2.  **å‘é‡æ¨¡å‹**: Qwen3-Embedding-8B,ç”Ÿæˆ1024ç»´å‘é‡
    
3.  **æ‰‹åŠ¨RRFèåˆ**: å› ES 9.0+ RRFéœ€å•†ä¸šè®¸å¯è¯,å®ç°æ‰‹åŠ¨èåˆç®—æ³• `score = 1/(k+rank)`
    
4.  **åˆ†ç±»ç´¢å¼•**: `_get_dynamic_es_index(category)`æ ¹æ®åˆ†ç±»åŠ¨æ€åˆ‡æ¢ESç´¢å¼•
    
5.  **å¯é…ç½®å‚æ•°**: `ES_VECTOR_CANDIDATES`ï¼ˆå‘é‡æ£€ç´¢å€™é€‰æ•°ï¼‰, `ES_TEXT_CANDIDATES`ï¼ˆå…¨æ–‡æ£€ç´¢å€™é€‰æ•°ï¼‰, `ES_RRF_K`ï¼ˆRRFå¹³æ»‘å¸¸æ•°ï¼‰, `ES_SEARCH_SIZE`ï¼ˆæœ€ç»ˆè¿”å›Top-Nï¼‰

#### é˜¶æ®µä¸ƒ: æ–‡æ¡£è¿‡æ»¤

**æ ¸å¿ƒåŠŸèƒ½**: ä½¿ç”¨LLMåˆ¤æ–­æ–‡æ¡£ç›¸å…³æ€§,å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†

**ä»£ç å®ç°**ï¼š

```python
async def _filter_chunks_parallel(doc_chunks, query, category):
    # å¤šçº¿ç¨‹å¹¶è¡Œè¿‡æ»¤
    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(_filter_single_chunk, chunk, query) 
                   for chunk in doc_chunks]
        
        for future, idx in futures:
            is_relevant, thinking = future.result()
            # å‘é€å®æ—¶è¿›åº¦
            await sse_manager.send_event("filter_progress", 
                                        {"current": idx+1, "total": len(doc_chunks)})
```

**å¤šçº¿ç¨‹å¹¶è¡Œ**: `ThreadPoolExecutor(max_workers=3)`æœ€å¤š3ä¸ªçº¿ç¨‹åŒæ—¶å¤„ç†

**çº¿ç¨‹ä¸“å±LLM**: æ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„`filter_llm`å®ä¾‹ï¼Œé¿å…çº¿ç¨‹å®‰å…¨é—®é¢˜

#### é˜¶æ®µå…«: ç»“è®ºç”Ÿæˆ

**æ ¸å¿ƒåŠŸèƒ½**: åŸºäºè¿‡æ»¤åçš„æ–‡æ¡£ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

**ä»£ç å®ç°**ï¼š

```python
async def generate_conclusion(doc_chunks, query):
    # è°ƒç”¨Conclusion LLM
    conclusion = await conclusion_llm.stream_chat([
        {"role": "system", "content": CONCLUSION_SYSTEM_PROMPT},
        {"role": "user", "content": f"æ–‡æ¡£:{doc_chunks}\né—®é¢˜:{query}"}
    ])
    # SSEæµå¼è¿”å›
    async for chunk in conclusion:
        await sse_manager.send_event("streaming_content", {"content": chunk})
```

**æ–‡æ¡£æ³¨å…¥**: å°†ç¼“å­˜çš„`relevant_doc_chunks`æ³¨å…¥åˆ°æç¤ºè¯

**æ¥æºè¿½è¸ª**: è¿”å›ç»“æœåŒ…å«`sources`å­—æ®µ,è®°å½•æ–‡æ¡£æ¥æº

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.10+
- PostgreSQL (æ¨è 13+)
- Elasticsearch 7.0+
- Redis (å¯é€‰ï¼Œç”¨äºç¼“å­˜)

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/Apple-Blossom23/DeepResearchAgent.git
cd DeepResearchAgent
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨ venv
python -m venv .venv
.venv\Scripts\activate  # Windows
# æˆ–
source .venv/bin/activate  # macOS/Linux

# æˆ–ä½¿ç”¨ conda
conda create -n deep_research python=3.10
conda activate deep_research
```

### 3. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 4. é…ç½®ç¯å¢ƒå˜é‡

å¤åˆ¶ `.env.example` ä¸º `.env` å¹¶é…ç½®ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```env
# ç¯å¢ƒé…ç½®
ENV=local  # local/dev/prod

# APIé…ç½®
DASHSCOPE_API_KEY=your_api_key_here
DASHSCOPE_BASE_URL=https://your-api-base-url

# æ¨¡å‹é…ç½®
DEFAULT_MODEL_NAME=your_default_model
PLANNING_MODEL_NAME=your_planning_model
CONCLUSION_MODEL_NAME=your_conclusion_model
FILTER_MODEL_NAME=your_filter_model

# åµŒå…¥æ¨¡å‹é…ç½®
EMBEDDING_ONLINE_URL=https://your-embedding-url

# æ•°æ®åº“é…ç½®
DB_HOST=localhost
DB_PORT=5432
DB_NAME=postgres_dev
DB_USER=postgres
DB_PASSWORD=your_db_password

# Elasticsearché…ç½®
ES_HOST=localhost
ES_PORT=9200
ES_INDEX=your_index

ES_AUTH=Basic base64_credentials

# MCPé…ç½®
MCP_SERVER_HOST=0.0.0.0
MCP_SERVER_PORT=8988
```

### 5. åˆå§‹åŒ–æ•°æ®åº“

```bash
# è¿è¡Œæ•°æ®åº“è¿ç§»
python -c "
from db_pool_manager import DatabasePoolManager
import asyncio
asyncio.run(DatabasePoolManager.initialize_pools())
"
```

### 6. å¯åŠ¨æœåŠ¡

#### å¼€å‘æ¨¡å¼

```bash
# å¯åŠ¨ä¸»æœåŠ¡
python run.py

# æˆ–ä½¿ç”¨å¯åŠ¨è„šæœ¬
bash start_dev.sh
```

#### ç”Ÿäº§æ¨¡å¼

```bash
# ä½¿ç”¨ç”Ÿäº§å¯åŠ¨è„šæœ¬
bash start_prod.sh
```

### 7. è®¿é—®åº”ç”¨

- **mcpæœåŠ¡ç«¯**: http://localhost:8988
- **webç•Œé¢**: http://localhost:8989/static/index.html

## ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ç”¨æ³•

#### 1. å‘½ä»¤è¡Œæ¨¡å¼

```python
# ç›´æ¥è¿è¡Œä¸»ç¨‹åº
python run.py

```

#### 2. SSEæµå¼å“åº”

```javascript
const eventSource = new EventSource('http://localhost:8000/api/stream');

eventSource.onmessage = function(event) {
    const data = JSON.parse(event.data);
    console.log('æ”¶åˆ°:', data);
};

eventSource.onerror = function(event) {
    console.log('è¿æ¥é”™è¯¯');
};
```

### é«˜çº§åŠŸèƒ½

#### è‡ªå®šä¹‰å·¥ä½œæµæ¨¡æ¿

åœ¨ `workflow_templates.py` ä¸­å®šä¹‰è‡ªå®šä¹‰æ¨¡æ¿ï¼š

```python
CUSTOM_TEMPLATE = {
    "name": "custom_workflow",
    "description": "è‡ªå®šä¹‰å·¥ä½œæµç¨‹",
    "steps": [
        {"type": "tool_call", "tool": "custom_tool"},
        {"type": "reasoning", "prompt": "custom_prompt"}
    ]
}
```

#### å·¥å…·é…ç½®

é€šè¿‡ `config.py` çš„ `TOOL_WHITELIST_MAPPING` æ§åˆ¶ä¸åŒ workflow åˆ†ç±»å…è®¸è°ƒç”¨çš„ MCP å·¥å…·ã€‚

```python
TOOL_WHITELIST_MAPPING = {
    "research-general": [
        "search_documents",
        "conclude_document_chunks",
    ],
    "technical-troubleshooting": [
        "search_documents",
        "conclude_document_chunks",
    ],
    "default": [
        "search_documents",
        "conclude_document_chunks",
    ],
}
```

#### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export LOG_LEVEL=DEBUG

# è¿è¡ŒæœåŠ¡
python run.py
```

## æµ‹è¯•

### è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_sse_manager.py -v

# è¿è¡Œè¦†ç›–ç‡æµ‹è¯•
pytest --cov=. tests/
```

### æ€§èƒ½æµ‹è¯•

```bash
# è¿è¡Œè¯„ä¼°æµ‹è¯•
python eval_runner.py
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
DeepResearchAgent/
â”œâ”€â”€ ReAct_Workflow.py           # ReActå·¥ä½œæµå¼•æ“
â”œâ”€â”€ ReAct_Events.py             # äº‹ä»¶å¤„ç†
â”œâ”€â”€ ReAct_Tools.py              # å·¥å…·å®šä¹‰ï¼ˆé€šè¿‡MCPè°ƒç”¨ï¼‰
â”œâ”€â”€ tools.py                    # MCPå·¥å…·æœåŠ¡ç«¯ï¼ˆFastMCPï¼‰
â”œâ”€â”€ fast_mcp_client.py          # MCPå®¢æˆ·ç«¯
â”œâ”€â”€ workflow_*.py               # å·¥ä½œæµç›¸å…³
â”œâ”€â”€ web/                        # Webç•Œé¢
â”‚   â”œâ”€â”€ app.js                  # å‰ç«¯é€»è¾‘
â”‚   â”œâ”€â”€ index.html              # ä¸»é¡µé¢
â”‚   â””â”€â”€ styles.css              # æ ·å¼æ–‡ä»¶
â”œâ”€â”€ ğŸ“ db/                      # æ•°æ®åº“
â”‚   â””â”€â”€ migrations/             # æ•°æ®åº“è¿ç§»
â”œâ”€â”€ ğŸ“ tests/                   # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ ğŸ“ scripts/                 # è„šæœ¬å·¥å…·
â”œâ”€â”€ ğŸ“„ run.py                   # ä¸»å¯åŠ¨æ–‡ä»¶
â”œâ”€â”€ ğŸ“„ external_api_server.py   # å¤–éƒ¨APIæœåŠ¡
â”œâ”€â”€ ğŸ“„ config.py                # é…ç½®ç®¡ç†
â”œâ”€â”€ ğŸ“„ requirements.txt         # ä¾èµ–åˆ—è¡¨
â””â”€â”€ ğŸ“„ README.md               # é¡¹ç›®æ–‡æ¡£
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

| å˜é‡å | è¯´æ˜ | ç¤ºä¾‹å€¼ | å¿…éœ€ |
|--------|------|--------|------|
| `ENV` | è¿è¡Œç¯å¢ƒ | local/dev/prod | âœ… |
| `DASHSCOPE_API_KEY` | APIå¯†é’¥ | your_key | âœ… |
| `DB_HOST` | æ•°æ®åº“ä¸»æœº | localhost | âœ… |
| `ES_HOST` | Elasticsearchä¸»æœº | localhost | âœ… |
| `DEFAULT_MODEL_NAME` | é»˜è®¤æ¨¡å‹åç§° | your_model | âœ… |

### æ•°æ®åº“é…ç½®

```sql
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE postgres_dev;

-- åˆ›å»ºç”¨æˆ·
CREATE USER postgres WITH PASSWORD 'your_password';

-- æˆæƒ
GRANT ALL PRIVILEGES ON DATABASE postgres_dev TO postgres;
```

### Elasticsearché…ç½®

```bash
# å®‰è£…Elasticsearch (Docker)
docker run -d \
  --name elasticsearch \
  -p 9200:9200 \
  -p 9300:9300 \
  -e "discovery.type=single-node" \
  -e "xpack.security.enabled=false" \
  elasticsearch:7.17.0
```

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°å·¥å…·

1. åœ¨ `ReAct_Tools.py` ä¸­å®šä¹‰å·¥å…·
2. åœ¨é…ç½®ä¸­æ·»åŠ å·¥å…·æè¿°
3. æ›´æ–°å·¥å…·ç™½åå•æ˜ å°„

### è‡ªå®šä¹‰å·¥ä½œæµ

1. åˆ›å»ºå·¥ä½œæµæ¨¡æ¿ç±»
2. å®šä¹‰æ­¥éª¤åºåˆ—
3. é…ç½®LLMå‚æ•°

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export LOG_LEVEL=DEBUG

# è¿è¡ŒæœåŠ¡
python run.py
